{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/gerald/Documents/CPD/repository/LifelongInformationRetrieval\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Clustering\n",
    "The objective of the current notebook is to cluster the queries of the datasets, such same topic query remains in a same cluster. The proposed methods remains simple, it use $K$-Means algorithm on vectorised sentences. To get sentence vector we use the **CLS** token of *BERT* classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from lire.data_tools.dataset import MSMarco\n",
    "import pandas as pd\n",
    "\n",
    "data_folder   = \"/media/gerald/00B1B02B44A76AB2/CPD/data\"\n",
    "train_queries = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"train\", data_folder)\n",
    "dev_queries   = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"dev\", data_folder)\n",
    "eval_queries  = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"eval\", data_folder)\n",
    "queries_set   = pd.concat([train_queries, dev_queries, eval_queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of query: \" number of times congress voted to repeal aca \"\n"
     ]
    }
   ],
   "source": [
    "query_example = queries_set.iloc[15][1]\n",
    "print('Example of query: \"', query_example, '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Compare Language Model for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'san', 'itiz', 'er', 'Ä temperature', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(query_example, return_tensors=\"pt\")\n",
    "print(tokenizer.convert_ids_to_tokens(inputs.input_ids.squeeze().tolist()))\n",
    "sequence_output, all_layer_output = model(**inputs, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_a = 'What is a transformer model in deep learning ?'\n",
    "query_b = 'Why transformers models are so efficient in deep learning ?'\n",
    "query_c = 'What is the coronavirus ?'\n",
    "query_d = 'The pandemic of the coronavirus take place in late 2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want $sim(q_a, q_b)>sim(q_a, q_c) + \\epsilon_1 $ and that $sim(q_a, q_c) + \\epsilon_2 <sim(q_c, q_d)$, with larger possible $\\epsilon_1, \\epsilon_2$ values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(query_a, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "query_a_embed_cls = outputs[1][-1][0][0]\n",
    "\n",
    "inputs = tokenizer(query_b, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "query_b_embed_cls = outputs[1][-1][0][0]\n",
    "\n",
    "inputs = tokenizer(query_c, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "query_c_embed_cls = outputs[1][-1][0][0]\n",
    "\n",
    "inputs = tokenizer(query_d, return_tensors=\"pt\")\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "query_d_embed_cls = outputs[1][-1][0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing using scalar product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(123.7903, grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.einsum(\"i, i -> \",query_a_embed_cls, query_b_embed_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(124.4663, grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.einsum(\"i, i -> \",query_a_embed_cls, query_c_embed_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(122.7851, grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.einsum(\"i, i -> \",query_b_embed_cls, query_c_embed_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(119.3706, grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.einsum(\"i, i -> \",query_b_embed_cls, query_d_embed_cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(120.1931, grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.einsum(\"i, i -> \",query_c_embed_cls, query_d_embed_cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing using l2 distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1632, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(((query_a_embed_cls - query_b_embed_cls)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2444, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(((query_a_embed_cls - query_c_embed_cls)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2862, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(((query_b_embed_cls - query_c_embed_cls)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7310, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(((query_b_embed_cls - query_d_embed_cls)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5191, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(((query_c_embed_cls - query_d_embed_cls)**2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sentence-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0c43126075e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sentences are encoded by calling model.encode()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery_a_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mquery_b_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mquery_c_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mquery_d_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_a' is not defined"
     ]
    }
   ],
   "source": [
    "#Sentences are encoded by calling model.encode()\n",
    "query_a_embed = model.encode(query_a)\n",
    "query_b_embed = model.encode(query_b)\n",
    "query_c_embed = model.encode(query_c)\n",
    "query_d_embed = model.encode(query_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = util.pytorch_cos_sim(query_a_embed, query_b_embed)\n",
    "print(\"cos(a, b) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_a_embed, query_c_embed)\n",
    "print(\"cos(a, c) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_b_embed, query_c_embed)\n",
    "print(\"cos(b, x) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_b_embed, query_d_embed)\n",
    "print(\"cos(b, d) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_c_embed, query_d_embed)\n",
    "print(\"cos(c, d) = \", cos_sim.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sentence-distilbert\n",
    "\n",
    "This model is used by default in the query clustering example shown in sentence-transformer [repository](https://github.com/UKPLab/sentence-transformers/blob/master/examples/applications/clustering/fast_clustering.py)\n",
    "We use it to create the dataset **MSMarcoPassageRankingTopicQueryDataset**, however remarks that it is easy to create an other dataset based on topics deriving the class with only a different *configuration_path* attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-quora-ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_a_embed = model.encode(query_a)\n",
    "query_b_embed = model.encode(query_b)\n",
    "query_c_embed = model.encode(query_c)\n",
    "query_d_embed = model.encode(query_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos(a, b) =  0.718645453453064\n",
      "cos(a, c) =  0.3546810448169708\n",
      "cos(b, c) =  0.32943886518478394\n",
      "cos(b, d) =  0.45006805658340454\n",
      "cos(c, d) =  0.4905753433704376\n"
     ]
    }
   ],
   "source": [
    "cos_sim = util.pytorch_cos_sim(query_a_embed, query_b_embed)\n",
    "print(\"cos(a, b) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_a_embed, query_c_embed)\n",
    "print(\"cos(a, c) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_b_embed, query_c_embed)\n",
    "print(\"cos(b, c) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_b_embed, query_d_embed)\n",
    "print(\"cos(b, d) = \", cos_sim.item())\n",
    "cos_sim = util.pytorch_cos_sim(query_c_embed, query_d_embed)\n",
    "print(\"cos(c, d) = \", cos_sim.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.Clustering using sentence bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "embedding_cache_path = \"/local/gerald/CPD/data/query_embeddings.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to https://www.sbert.net/examples/applications/clustering/README.html (fast clustering)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def community_detection(embeddings, threshold=0.75, min_community_size=10, init_max_size=1000):\n",
    "    \"\"\"\n",
    "    Function for Fast Community Detection\n",
    "    Finds in the embeddings all communities, i.e. embeddings that are close (closer than threshold).\n",
    "    Returns only communities that are larger than min_community_size. The communities are returned\n",
    "    in decreasing order. The first element in each list is the central point in the community.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute cosine similarity scores\n",
    "    cos_scores = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "\n",
    "    # Minimum size for a community\n",
    "    top_k_values, _ = cos_scores.topk(k=min_community_size, largest=True)\n",
    "\n",
    "    # Filter for rows >= min_threshold\n",
    "    extracted_communities = []\n",
    "    for i in range(len(top_k_values)):\n",
    "        if top_k_values[i][-1] >= threshold:\n",
    "            new_cluster = []\n",
    "\n",
    "            # Only check top k most similar entries\n",
    "            top_val_large, top_idx_large = cos_scores[i].topk(k=init_max_size, largest=True)\n",
    "            top_idx_large = top_idx_large.tolist()\n",
    "            top_val_large = top_val_large.tolist()\n",
    "\n",
    "            if top_val_large[-1] < threshold:\n",
    "                for idx, val in zip(top_idx_large, top_val_large):\n",
    "                    if val < threshold:\n",
    "                        break\n",
    "\n",
    "                    new_cluster.append(idx)\n",
    "            else:\n",
    "                # Iterate over all entries (slow)\n",
    "                for idx, val in enumerate(cos_scores[i].tolist()):\n",
    "                    if val >= threshold:\n",
    "                        new_cluster.append(idx)\n",
    "\n",
    "            extracted_communities.append(new_cluster)\n",
    "\n",
    "    # Largest cluster first\n",
    "    extracted_communities = sorted(extracted_communities, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "    # Step 2) Remove overlapping communities\n",
    "    unique_communities = []\n",
    "    extracted_ids = set()\n",
    "\n",
    "    for community in extracted_communities:\n",
    "        add_cluster = True\n",
    "        for idx in community:\n",
    "            if idx in extracted_ids:\n",
    "                add_cluster = False\n",
    "                break\n",
    "\n",
    "        if add_cluster:\n",
    "            unique_communities.append(community)\n",
    "            for idx in community:\n",
    "                extracted_ids.add(idx)\n",
    "\n",
    "    return unique_communities\n",
    "\n",
    "def completing_cluster(cluster_center, data):\n",
    "    clusters = [[] for x in cluster_center]\n",
    "    data = torch.Tensor(data)\n",
    "    cluster_center = torch.Tensor(cluster_center)\n",
    "    for i, d in zip(tqdm.notebook.trange(len(data)),data):\n",
    "        cos_sim = util.pytorch_cos_sim(cluster_center, d)\n",
    "        clusters[cos_sim.argmax()].append(i)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-computed embeddings from disc\n",
      "Number of clusters discovered  2727\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0eedd1079d426e836216d05e7c9dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1010916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-90b9494217cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of clusters discovered \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mcluster_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mcluster_completed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompleting_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_center\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_completed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/local/gerald/CPD/data/cluster_completed2.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-afbca442e63a>\u001b[0m in \u001b[0;36mcompleting_cluster\u001b[0;34m(cluster_center, data)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mcluster_center\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch_cos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_center\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/conda/envs/lire/lib/python3.9/site-packages/sentence_transformers/util.py\u001b[0m in \u001b[0;36mpytorch_cos_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0ma_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mb_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/conda/envs/lire/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   3786\u001b[0m                 normalize, (input,), input, p=p, dim=dim, eps=eps, out=out)\n\u001b[1;32m   3787\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3788\u001b[0;31m         \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3789\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3790\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/conda/envs/lire/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/conda/envs/lire/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# defining the model with embedding will be used for clustering\n",
    "model = SentenceTransformer('stsb-roberta-large')\n",
    "# model = SentenceTransformer('distilbert-base-nli-stsb-quora-ranking')\n",
    "\n",
    "embedding_cache_path = \"/local/gerald/CPD/data/query_embeddings2.pkl\"\n",
    "\n",
    "\n",
    "\n",
    "corpus_sentences = queries_set[1].tolist() \n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(embedding_cache_path):\n",
    "    print(\"Encode the corpus. This might take a while\")\n",
    "    corpus_embeddings = model.encode(corpus_sentences, show_progress_bar=True, convert_to_numpy=True)\n",
    "    print(\"Store file on disc\")\n",
    "    with open(embedding_cache_path, \"wb\") as fOut:\n",
    "        pickle.dump({'sentences': corpus_sentences, 'embeddings': corpus_embeddings}, fOut)\n",
    "\n",
    "print(\"Load pre-computed embeddings from disc\")\n",
    "with open(embedding_cache_path, \"rb\") as fIn:\n",
    "    cache_data = pickle.load(fIn)\n",
    "corpus_sentences = cache_data['sentences']\n",
    "corpus_embeddings = cache_data['embeddings']\n",
    "corpus_sentences_sub = corpus_sentences[:50000]\n",
    "corpus_embeddings_sub = corpus_embeddings[:50000]\n",
    "clusters = community_detection(corpus_embeddings_sub, threshold=0.8,\n",
    "                               min_community_size=2, init_max_size=1000)\n",
    "cluster_sentences = [[corpus_sentences_sub[s] for s in cluster] \n",
    "                     for cluster in clusters]\n",
    "print(\"Number of clusters discovered \", len(cluster_sentences))\n",
    "cluster_center = np.vstack([corpus_embeddings[cluster[0]] for cluster in clusters])\n",
    "cluster_completed = completing_cluster(cluster_center, corpus_embeddings) \n",
    "torch.save(cluster_completed,\"/local/gerald/CPD/data/cluster_completed2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cluster_center, \"/local/gerald/CPD/data/cluster_center2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embedding_cache_path, \"rb\") as fIn:\n",
    "    cache_data = pickle.load(fIn)\n",
    "corpus_sentences = cache_data['sentences']\n",
    "corpus_embeddings = cache_data['embeddings']\n",
    "clusters_final = torch.load(\"/local/gerald/CPD/data/cluster_completed2.pth\")\n",
    "cluster_sentences = [[corpus_sentences[s] for s in cluster] for cluster in clusters_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what county is hollywood fl',\n",
       " \"how far is harrah's casino from the french quarter\",\n",
       " 'what sea is canary islands in',\n",
       " 'what county is denham springs louisiana in',\n",
       " 'when did allies land on beaches in normandy france on d day',\n",
       " 'how many soldiers died storming the beaches of normandy',\n",
       " 'what are faverolle chickens',\n",
       " 'where does ellie louise live',\n",
       " 'when were the new orleans pelicans formed',\n",
       " 'where have laura ingalls wilder lived',\n",
       " 'what is the hallux of the foot',\n",
       " 'seafield inpatient number',\n",
       " 'what breed of canary is a pure white one',\n",
       " 'demographics of holly springs nc population',\n",
       " 'wells fargo telephone number',\n",
       " 'what county is newhall',\n",
       " 'how far is the td gardens from hyatt regency',\n",
       " 'is tulane a private university',\n",
       " 'what county is crawfordville fl',\n",
       " 'what county is north port fl in',\n",
       " 'what county is hendersonville tn in',\n",
       " 'when did us storm normandy beach',\n",
       " 'what county is holiday, fl',\n",
       " 'navy federal cliffdale branch phone number',\n",
       " 'did finn ever throw balloons at rachel',\n",
       " 'what county is hallandale beach fl',\n",
       " 'where is hallandale beach florida located',\n",
       " 'where is hall county',\n",
       " 'how far radisson resort orlando - celebration from disney world',\n",
       " 'what region is mustang island state lrm',\n",
       " 'george harrison what is life dancer rabinowitz',\n",
       " 'where is cape canaveral located in florida',\n",
       " 'what county is bonita springs, fl',\n",
       " 'where was the boothurst mansion new castle de',\n",
       " 'where did the shoshone people do the chicken dance',\n",
       " 'what county is dover, fl in',\n",
       " 'where is the villages, fl located',\n",
       " 'allenhurst ga what county',\n",
       " 'can an lvn be hired as a adon for home health',\n",
       " 'what county is deland fl',\n",
       " 'what parish is clinton louisiana in',\n",
       " 'fluvanna county population',\n",
       " 'what is zip code for ft lauderdale fl',\n",
       " 'what county is ft payne al in',\n",
       " 'what county is tequesta fl',\n",
       " 'how big is lake conley in florida',\n",
       " 'what time zone is plantation fl',\n",
       " 'wells fargo fl personal routing number',\n",
       " 'what county is bell fl',\n",
       " 'who plays haley in the florida project',\n",
       " 'what golf club was condoleezza rice alarm to join',\n",
       " 'what castle is at disneyland paris',\n",
       " 'what county is 33952',\n",
       " 'what county is falfurrias?',\n",
       " 'how far is wildwood to atlantic city',\n",
       " 'war storming normandy beach',\n",
       " 'what tampa port carnival',\n",
       " 'what county is beside floyd county ky',\n",
       " 'how much is breakfast at ritz carlton doha',\n",
       " 'where is sally beauty holdings, inc. headquarters',\n",
       " 'what is the name of the parking garage on fannin st in houston',\n",
       " 'what county is minneola fl in',\n",
       " 'what county is galway in',\n",
       " 'where is hurlburt field, fl?',\n",
       " 'is the villa florence hotel haunted',\n",
       " 'what county is new haven ct located in',\n",
       " 'where is the faze house in la',\n",
       " 'what county is hyannis ma',\n",
       " \"where is devil's den florida\",\n",
       " 'what part of the body is hallux',\n",
       " 'where is westville, fl.',\n",
       " 'when was galleon farms founded',\n",
       " 'what county is baco raton fl in',\n",
       " 'where is halsey from',\n",
       " 'who is hrethel in beowulf',\n",
       " 'how far is fort lauderdale to deerfield beach fl',\n",
       " 'canary wharf is in which london borough',\n",
       " 'where is youngstown fl',\n",
       " 'hotels on esplanade in new orleans trivago',\n",
       " 'what is the name of ft lauderdale beach',\n",
       " 'in what city did henry ford made his first company',\n",
       " 'is tamron hall married to lawrence o-donnell',\n",
       " 'the refuge ocklawaha fl reviews',\n",
       " 'what county is fairfield texas',\n",
       " 'what county is hoyt lakes mn in',\n",
       " 'what is fremont villas',\n",
       " 'where is hallasan located',\n",
       " 'what county is lauderhill fl',\n",
       " 'what beach is florence close to',\n",
       " 'where was florence nightingale from',\n",
       " 'what florida county is tallahassee in',\n",
       " 'where is st clair beach ontario',\n",
       " 'why is colosseum called flavian ampitheatre',\n",
       " 'where is rotterdam',\n",
       " 'which toe is the hallux',\n",
       " 'canary islands do they belong to EU',\n",
       " 'what about h&f museum?',\n",
       " 'what county is ellison bay',\n",
       " 'can i apply fablon to bathroom tiles',\n",
       " 'what county is howard beach ny',\n",
       " 'in what county is bal harbour fl',\n",
       " 'wealthy zip codes in gainesville fl',\n",
       " 'is chelsea clinton hot',\n",
       " 'where is rotonda fl',\n",
       " 'what county is blairs,va',\n",
       " 'what county is fort walton beach fl in',\n",
       " 'what county is holly springs nc in',\n",
       " 'what county is bonita springs fl?',\n",
       " 'what is listello',\n",
       " 'what is the zip code for mascotte florida',\n",
       " 'what is hallux varus',\n",
       " 'what county is niceville, fl in',\n",
       " 'what county is reddick fl',\n",
       " 'where is wandana hall in geelong',\n",
       " 'what city is green cove springs florida near?',\n",
       " 'what county is hendersonville',\n",
       " \"what's the weather in fort lauderdale florida\",\n",
       " 'what car does the hennessey venom start off with',\n",
       " 'how far is it from orlando to new orleans',\n",
       " 'where is zealand island',\n",
       " 'hotels in wayne, nj',\n",
       " 'what county is havana fl in',\n",
       " 'what is organelles',\n",
       " 'what county is halls, tn in',\n",
       " 'what is a vanilla halva',\n",
       " 'what is vauxhall in london',\n",
       " 'what does foh stand for urban dictionary',\n",
       " 'what county is windermere florida in',\n",
       " 'what is gaye allen cook address in florence, sc',\n",
       " 'fort lauderdale florida cost of living',\n",
       " 'when was the wells fargo building built in appomattox va',\n",
       " 'what county is shreve oh located',\n",
       " 'holiday inn express in plantation fl',\n",
       " 'what county is galena in?',\n",
       " 'what county is the villages, fl in',\n",
       " 'what county is ellicott city md',\n",
       " 'what episode of constantine is juliana harkavy in',\n",
       " 'what plant zone is callahan, fl in',\n",
       " 'what county is plantation fl',\n",
       " \"when is rapper nelly's birthday\",\n",
       " 'when did nat hickey get drafted in the nba',\n",
       " 'who is nell hott',\n",
       " 'what airlines are near hutchinson island florida',\n",
       " 'what constitutes residency in florida',\n",
       " 'what country does violetta come from',\n",
       " 'is deland fl',\n",
       " 'where is port st richey florida',\n",
       " 'what hotels are at disney springs orlando',\n",
       " 'what is a gallette',\n",
       " 'which county is tavernier fl in?',\n",
       " 'what is florida electrical unlicensed activity',\n",
       " 'convert your backyard flundryntonpropane',\n",
       " 'what county is parkland fl in?',\n",
       " 'what county is lake frederick va',\n",
       " 'what county is pell city al',\n",
       " 'what county is reddick, fl in',\n",
       " 'who is funneh',\n",
       " 'what is the rotary club',\n",
       " 'what county is hope sound fl in',\n",
       " \"can i take flonase while i'm on lumigan\",\n",
       " 'what parish is donaldsonville la in',\n",
       " 'what county is ocean ridge fl in',\n",
       " 'which holiday inn has a breeze walk in orlando fl',\n",
       " 'what county is city of tallahassee fl in',\n",
       " 'what county is foster city ca',\n",
       " 'what county is fern park fl in',\n",
       " 'what type of car is mcqueen',\n",
       " 'where is celine dion florida home',\n",
       " 'what is the zip code for fort lauderdale fl',\n",
       " 'where is ponte vedra fl',\n",
       " 'housing costs cocoa florida',\n",
       " 'what is hall county',\n",
       " 'is flam cabinet equipment?',\n",
       " 'what was newport music hall',\n",
       " 'what are the organelles',\n",
       " 'how far is hilton head sc to florence sc',\n",
       " 'where is the hurlingham polo club',\n",
       " 'where is cheyenne wells colorado',\n",
       " 'what county is florham park, nj',\n",
       " 'where does the pulmonary artery take blonde',\n",
       " 'how far is lynn haven fl to gainesville fl',\n",
       " 'what part of california was jayden bartels born in',\n",
       " 'who owned half moon cay before holland?',\n",
       " 'haven when does audrey kiss nathans cheek',\n",
       " 'what county is pompano beach fl located',\n",
       " 'what county is town of holly springs north carolina',\n",
       " 'what county is freeport fl',\n",
       " 'fernandina beach fl police non emergengy phone number',\n",
       " 'what county is lecanto fl in',\n",
       " 'where is the callanwolde mansion atlanta',\n",
       " 'how to get rare floette',\n",
       " 'what is zyflamend',\n",
       " 'hotels in euless tx',\n",
       " 'what county is old town, fl in?',\n",
       " 'what airline flies from orlando to fort lauderdale, fl',\n",
       " 'how far is wake islands from royersford,pa',\n",
       " 'what county is bunnell fl in',\n",
       " 'what county is lutz, fl in',\n",
       " 'what county is punta gorda fl',\n",
       " 'why was the cape hatteras lighthouse moved?',\n",
       " 'where is newhall california',\n",
       " 'which part of the state is holly springs, nc located',\n",
       " 'how far is navarre fl from eglin afb',\n",
       " 'where is lauderhill florida',\n",
       " 'what county is st helena island',\n",
       " 'what county in flushing ny',\n",
       " 'what county is ft walton beach fl',\n",
       " 'what county is ncbc gulfport in',\n",
       " 'what county is hallandale beach in',\n",
       " 'what county is chattahoochee fl in',\n",
       " 'is carrageenan halal',\n",
       " 'who called megyn kelly a dumb blonde',\n",
       " 'what is hayley noelle leblanc from',\n",
       " 'what is a rotary club',\n",
       " 'what county is seminole fl in',\n",
       " 'what controversial about dorothy hale painting',\n",
       " 'what city is callahan county in',\n",
       " 'what is the county for ferndale fl',\n",
       " 'what town is vineyard haven ma in',\n",
       " 'what county is nettles island fl',\n",
       " 'what does the fema public officer od',\n",
       " 'how far is omni new orleans hotel to the convention center',\n",
       " 'wax museum in nc',\n",
       " 'who is the code name for the last name halliwer?',\n",
       " 'what carnival ships have cove balcony',\n",
       " 'what county is callahan florida in',\n",
       " 'where located port richey in florida',\n",
       " 'flo rider in the club lyrics',\n",
       " 'what city is the villages in florida',\n",
       " 'florida condos what do hoa dues average',\n",
       " 'when was the beach club two in hallandale,fl built?',\n",
       " 'what town is the flume gorge in',\n",
       " 'where is beverly hills, fl',\n",
       " 'what county is canvey island in',\n",
       " 'what county is ridge manor in, fl',\n",
       " 'what county is bloomingdale ca',\n",
       " 'what county is key largo fl in',\n",
       " 'what county is holiday fl',\n",
       " 'what county is wilton manors, fl',\n",
       " 'what county is quincy fl',\n",
       " 'telephone number for wells fargo in easley south carolina',\n",
       " 'wells fargo phone num',\n",
       " 'what county is fort lauderdale fl in',\n",
       " 'what county for hollywood fl',\n",
       " 'what type of genre is galway girl',\n",
       " 'where is reynolds plantation in georgia',\n",
       " 'what county is lynn haven florida in',\n",
       " 'what county is temple terrace fl',\n",
       " 'what county is holiday fl in',\n",
       " 'how far was north galilee to south galilee',\n",
       " 'what is the rotary club all about',\n",
       " 'what county was dance founded in',\n",
       " 'what county is hampton fl',\n",
       " 'what region of the diencephalon coordinates homeostasis?',\n",
       " 'what nationality is the last name falldorf',\n",
       " 'who is laverne cox actress',\n",
       " 'where is cornell rd callahan fl',\n",
       " 'what album was jump by van halen',\n",
       " 'where is hanna wyoming',\n",
       " \"was sally field's mother an actress?\",\n",
       " 'definition florence nightingale',\n",
       " 'how far is it from ft lauderdale to orlando',\n",
       " 'who is flora merryweather and fauna',\n",
       " 'how far is hyannis from orleans',\n",
       " 'what county is homestead fl',\n",
       " 'does vlc android play flac files',\n",
       " 'inverness fl what county',\n",
       " 'what county is bushnell fl',\n",
       " 'what county is hawthorne fl',\n",
       " 'when did ballyhoos in tarpon springs close',\n",
       " 'which hilton in orlando has a water park',\n",
       " 'where does pinellas trail start',\n",
       " 'what county is pembroke pines fl in',\n",
       " 'what county is ocklawaha, fl',\n",
       " 'who makes hennessey cars',\n",
       " 'what county is lake buena vista fl in',\n",
       " 'what is hollandaise',\n",
       " 'what is howell-jolly bodies',\n",
       " 'in what county is tavernier fl',\n",
       " 'how far is cooper city fl to hollywood fl',\n",
       " 'what town in laffayette county was built before mayo',\n",
       " 'where is hale colorado?',\n",
       " 'what county is redington shores fl',\n",
       " 'what opera is nessun dorma from',\n",
       " 'what is hooey',\n",
       " 'what movie has chuck norris and sylvester stallone',\n",
       " 'which opera is nessun dorma from?',\n",
       " 'what are the atlantic charter and the yalta conference?',\n",
       " 'what county is lake panasoffkee fl in',\n",
       " 'what county is geneva fl in',\n",
       " 'why is carolyn meehan not on ctv news',\n",
       " 'how far is fannies on the beach from savannah beach and racquet club',\n",
       " 'club nautico dominican republic',\n",
       " 'what radio station are the new york yankees on in tampa fl',\n",
       " 'what is halal travel',\n",
       " 'club wyndham vacation resorts phone number',\n",
       " 'what county is florence, tx',\n",
       " 'what county is hastings, ny in',\n",
       " 'what county is celebration, fl',\n",
       " 'what county is bell fl in',\n",
       " 'what county is weatherford, tx',\n",
       " 'is farmingdale suffolk or nassau',\n",
       " 'what county is st petersburg fl',\n",
       " 'how many hilton hotels are in north scottsdale',\n",
       " 'what region is waxahachie tx',\n",
       " 'what county is molino fl in',\n",
       " 'what is the county of hendersonville, tn',\n",
       " 'which nba team plays in the conseco fieldhouse',\n",
       " 'what county is in st petersburg fl',\n",
       " 'where is the villages, fl',\n",
       " 'what county is coral gables fl',\n",
       " 'which city is villareal based',\n",
       " 'what county is reynolds plantation in',\n",
       " 'what county is chipley fl',\n",
       " 'where is newport beach ca universities',\n",
       " 'what is blippar halos',\n",
       " 'what would beyonce wear to the white party',\n",
       " 'where is frida kahlo blue house located',\n",
       " 'what town is tobay beach',\n",
       " 'what beaches can you drive on in nc',\n",
       " 'how far is it from cocoa beach fl to wet n wild orlando fl',\n",
       " 'what county is newhall ca in',\n",
       " 'where is tattershall castle',\n",
       " 'what is a nurse resident henry ford wyandotte',\n",
       " 'where is hahnville louisiana',\n",
       " 'what hotel in kansas city has a holidome',\n",
       " 'housing in frederick md',\n",
       " 'how far is destin fl and niceville fl',\n",
       " 'what is crime rate for new port richey fl',\n",
       " 'who wrote the soundtrack for annie hall',\n",
       " 'alachua fl is in what county',\n",
       " 'was laverne cox on wings',\n",
       " 'what is a villanelle',\n",
       " 'how many miles are there between Cordele Ha to Port Vharlotte Fl?',\n",
       " 'what does rotterdam zh nl stand for',\n",
       " 'what county is the city of seminole fl in',\n",
       " 'what county is seminole fl in?',\n",
       " 'what county is niceville fl in?',\n",
       " 'what county is city of belleair beach, fl in',\n",
       " 'what county is celebration, fl in',\n",
       " 'how far is the hilton strip in las vegas is from the orleans',\n",
       " 'how far is mia to fll',\n",
       " 'what is the population of havana florida',\n",
       " 'can you walk from sheerness to harty along the coast of the isle of sheppey',\n",
       " 'what county is fort lauderdale fl in?',\n",
       " 'what county is rehoboth beach, de,',\n",
       " 'what county is seminole, fl. in',\n",
       " 'what county is youngstown fl',\n",
       " 'what type of city is tallahassee fl',\n",
       " 'what van halen album has on fire',\n",
       " 'what is presidential reserve with wyndham resorts',\n",
       " 'what was the cause of death of shey faherty',\n",
       " 'is carla hall african american',\n",
       " 'what includes all the organelles',\n",
       " 'distance newport to fogarty beach',\n",
       " 'where in louisiana is henderson',\n",
       " 'where is chickity island',\n",
       " 'where is goodland fl,',\n",
       " 'where is hennessey performance located',\n",
       " 'where is hobe sound florida on map',\n",
       " 'hendersonville tn what county',\n",
       " 'where is the mardi gras held at that chases chickens',\n",
       " 'where is the two tennessee coast guard bases located',\n",
       " 'where is hernando beach in florida ?',\n",
       " 'where are the newport mansions located',\n",
       " 'population of holly springs nc',\n",
       " 'countryside haven alf phone number',\n",
       " 'when did laura ingalls wilder live',\n",
       " 'what is hallux',\n",
       " 'does the longhorn restaurant serves oysters rockefeller?',\n",
       " 'what kind of hair does lindsey vonn have',\n",
       " 'what county is lake harris florida',\n",
       " 'what is nassau hall',\n",
       " 'cox business omaha phone number',\n",
       " 'what county is oviedo fl in',\n",
       " 'what county is plant city fl in',\n",
       " 'villages of oriole condo association',\n",
       " 'what area is new benidorm called',\n",
       " \"who played annalise villa in tv's rosewood ?\",\n",
       " 'definition of flophouse',\n",
       " 'what city is  holloman afb',\n",
       " 'what county is rotterdam town ny in',\n",
       " 'what city zone is fleming island fl',\n",
       " 'what county is halliday nd in',\n",
       " 'what county is graceville florida',\n",
       " 'what county is city of new port richey fl in',\n",
       " 'what color is honduras colony',\n",
       " 'how old is grace e hallerin',\n",
       " 'population of lauderhill fl',\n",
       " 'in what county is ellenton fl',\n",
       " 'what county is haines city florida',\n",
       " 'what county is hendersonville tn?',\n",
       " 'what county is homestead, fl',\n",
       " 'what county is lovettsville va in',\n",
       " 'what ocean is honduras on',\n",
       " 'what show did marilu henner play on',\n",
       " 'what township is henryville, in',\n",
       " 'hyatt place opryland was far is to hyatt place downtown',\n",
       " 'where is fort lauderdale florida',\n",
       " 'is florida a homestead state',\n",
       " \"do anyone live in elvis presley's house in tupelo mississippi\",\n",
       " 'is shane king in the liberal party',\n",
       " 'when is bulk day in lauderhill, fl',\n",
       " 'where is queensborough sc',\n",
       " 'when is sydney mardi gras',\n",
       " 'nfl what is hof?',\n",
       " 'where is niceville fl.',\n",
       " 'what county is bonita beach fl',\n",
       " 'howey in the hills fl zip code',\n",
       " 'what county is elberta fl',\n",
       " 'what county is holly springs nc',\n",
       " 'who is grace halloran',\n",
       " 'who is hannah lee fowler',\n",
       " 'who is renee fleming',\n",
       " 'terrence mckinley coral gables',\n",
       " 'who owns lake norman auto sports inc in north carolina']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sentences[3540]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder    = \"/local/gerald/CPD/data\"\n",
    "embedding_path = \"/local/gerald/CPD/data/query_embeddings2.pkl\"\n",
    "cluster_path   = \"/local/gerald/CPD/data/cluster_completed2.pth\"\n",
    "cluster_center   = \"/local/gerald/CPD/data/cluster_center2.pth\"\n",
    "\n",
    "train_queries = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"train\", data_folder)\n",
    "dev_queries   = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"dev\", data_folder)\n",
    "eval_queries  = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"eval\", data_folder)\n",
    "train_qrels   = MSMarco.MSMarcoPassageRankingDataset.load_qrels(\"train\", data_folder)\n",
    "dev_qrels     = MSMarco.MSMarcoPassageRankingDataset.load_qrels(\"dev\", data_folder)\n",
    "qrels_set     = Qrels.merge_qrels(train_qrels, dev_qrels)\n",
    "\n",
    "queries_set   = pd.concat([train_queries, dev_queries, eval_queries])\n",
    "query_example = queries_set.iloc[11][1]\n",
    "print('Example of query: \"', query_example, '0\"')\n",
    "\n",
    "queries_sentences  = queries_set[1].tolist() \n",
    "queries_ids        = queries_set.index.values.tolist()\n",
    "queries_inv_ids    = {v:i for i, v in enumerate(queries_ids)}\n",
    "queries_ids_train  = len(train_queries)\n",
    "queries_ids_dev    = len(train_queries) + len(dev_queries)\n",
    "queries_ids_eval   = len(train_queries) + len(dev_queries) + len(eval_queries)\n",
    "clusters    = torch.load(cluster_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the split and looking for empty/too small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, dev_set, eval_set = [], [], [] \n",
    "for cluster in clusters:\n",
    "    train_set.append([])\n",
    "    dev_set.append([])\n",
    "    eval_set.append([])\n",
    "\n",
    "    for query in cluster:\n",
    "        if(str(queries_ids[query]) in qrels_set):\n",
    "            if(query < queries_ids_train):\n",
    "                train_set[-1].append(queries_ids[query])\n",
    "            elif(query < queries_ids_dev):\n",
    "                dev_set[-1].append(queries_ids[query])\n",
    "            elif(query < queries_ids_eval):\n",
    "                eval_set[-1].append(queries_ids[query])\n",
    "            else:\n",
    "                raise Exception(\"Irrelevant query id\")\n",
    "\n",
    "too_small_dev_cluster = [ i for i, cluster in enumerate(dev_set) if(len(cluster) <= 2)]\n",
    "too_small_eval_cluster = [ i for i, cluster in enumerate(eval_set) if(len(cluster) <= 2)]\n",
    "\n",
    "print(\"Number of dev sets that contains less than 2 queries : \", len(too_small_dev_cluster))\n",
    "print(\"Number of eval sets that contains less than 2 queries : \", len(too_small_eval_cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge  of too small cluster and loading needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(embedding_path, \"rb\") as fIn:\n",
    "    cache_data = pickle.load(fIn)\n",
    "corpus_sentences = cache_data['sentences']\n",
    "corpus_embeddings = cache_data['embeddings']\n",
    "\n",
    "clusters_to_merge = too_small_dev_cluster\n",
    "cluster_center = torch.load(\"/local/gerald/CPD/data/cluster_center2.pth\")\n",
    "\n",
    "clusters_center = torch.load(\"/local/gerald/CPD/data/cluster_center2.pth\")\n",
    "cluster_center_merged  = []\n",
    "cluster_center_reindex = []\n",
    "new_clusters = []\n",
    "\n",
    "# reindexing\n",
    "for i, cluster_center in enumerate(clusters_center):\n",
    "    if i not in clusters_to_merge:\n",
    "        cluster_center_merged.append(clusters_center[i])\n",
    "        cluster_center_reindex.append(i)\n",
    "        new_clusters.append(clusters[i])\n",
    "\n",
    "# much faster using pytorch\n",
    "cluster_center_merged  = torch.Tensor(cluster_center_merged)\n",
    "corpus_embeddings = torch.Tensor(corpus_embeddings)\n",
    "\n",
    "# merging\n",
    "for i, cluster_index in zip(tqdm.notebook.trange(len(clusters_to_merge)), clusters_to_merge):\n",
    "    cluster = clusters[cluster_index]\n",
    "    for query in cluster:\n",
    "        cos_sim = util.pytorch_cos_sim(cluster_center_merged, corpus_embeddings[query])\n",
    "        new_clusters[cos_sim.argmax()].append(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve agains the splits and save the clusters indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set, dev_set, eval_set = [], [], [] \n",
    "for cluster in new_clusters:\n",
    "    train_set.append([])\n",
    "    dev_set.append([])\n",
    "    eval_set.append([])\n",
    "    \n",
    "    for query in cluster:\n",
    "        if(str(queries_ids[query]) in qrels_set):\n",
    "            if(query < queries_ids_train):\n",
    "                train_set[-1].append(queries_ids[query])\n",
    "            elif(query < queries_ids_dev):\n",
    "                dev_set[-1].append(queries_ids[query])\n",
    "            elif(query < queries_ids_eval):\n",
    "                eval_set[-1].append(queries_ids[query])\n",
    "            else:\n",
    "                raise Exception(\"Irrelevant query id\")\n",
    "import json\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_train_stsb-roberta-large.json', 'w') as outfile:\n",
    "    json.dump(train_set, outfile, indent = 4)\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_dev_stsb-roberta-large.json', 'w') as outfile:\n",
    "    json.dump(dev_set, outfile, indent = 4)\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_eval_stsb-roberta-large.json', 'w') as outfile:\n",
    "    json.dump(eval_set, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Top1000 by topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/gerald/Documents/CPD/repository/LifelongInformationRetrieval\") \n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from lire.data_tools.dataset import MSMarco\n",
    "from lire.data_tools import data_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_train_stsb-roberta-large.json', 'r') as infile:\n",
    "    train_set = json.load(infile)\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_dev_stsb-roberta-large.json', 'r') as infile:\n",
    "    dev_set   = json.load(infile)\n",
    "with open('/web/gerald/public_html/lire_data/msmarco_topics_cleaned_eval_stsb-roberta-large.json', 'r') as infile:\n",
    "    eval_set  = json.load(infile)\n",
    "\n",
    "data_folder   = \"/media/gerald/00B1B02B44A76AB2/CPD/data\"\n",
    "train_queries = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"train\", data_folder)\n",
    "dev_queries   = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"dev\", data_folder)\n",
    "eval_queries  = MSMarco.MSMarcoPassageRankingDataset.load_queries(\"eval\", data_folder)\n",
    "queries_set   = pd.concat([train_queries, dev_queries, eval_queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queries_set_unique = set(queries_set.index.unique().tolist())\n",
    "data_folder = os.path.join(data_folder, \"MSMarcoPassageRankingDataset\")\n",
    "dev_top_1000_path = os.path.join(data_folder, \"dev-top-1000.data\")\n",
    "train_top_1000_path = os.path.join(data_folder, \"train-id-top-1000.data\")\n",
    "train_triplet_path = os.path.join(data_folder,'train_positive_negative.data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_inverse_cluster = {qid:cid for cid, c in enumerate(dev_set) for qid in c}\n",
    "train_inverse_cluster = {qid:cid for cid, c in enumerate(train_set) for qid in c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_filepath = os.path.join(data_folder, \"data.hdf5\")\n",
    "if(os.path.exists(hdf5_filepath)):\n",
    "    os.remove(hdf5_filepath)\n",
    "\n",
    "root = h5py.File(hdf5_filepath,'a')\n",
    "\n",
    "dev = root.create_group(\"dev\")\n",
    "dev_1000 = dev.create_group(\"dev-top-1000\")\n",
    "train = root.create_group(\"train\")\n",
    "train_1000 = train.create_group(\"train-top-1000\")\n",
    "train_triple = train.create_group(\"qid-pid-nid-cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing and counting nb lines, can be long\n",
      "Nb lines processed: 6668967\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 6980/6980 [00:00<00:00, 8001.23it/s]\n",
      "100%|ââââââââââ| 1/1 [00:39<00:00, 39.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "Preprocessing and counting nb lines, can be long\n",
      "Nb lines processed: 90000000\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-344770e3ee7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                  )\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m data_large.HDF5DatasetManager.batched_csv_to_hdf5(hdf5_filepath, train_1000.name,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                   \u001b[0mtrain_top_1000_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"did\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                   \u001b[0mgroup_by_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CPD/repository/LifelongInformationRetrieval/lire/data_tools/data_large.py\u001b[0m in \u001b[0;36mbatched_csv_to_hdf5\u001b[0;34m(cls, hdf5_file, group_path, csv_filepath, split, col_name, group_by_key, col_type, batch_size, group_by_func, dataset_compression)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing and counting nb lines, can be long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_lines\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;31m# checking coherence of data with given parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CPD/repository/LifelongInformationRetrieval/lire/data_tools/data_large.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing and counting nb lines, can be long\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_lines\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0;31m# checking coherence of data with given parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/conda/envs/lire/lib/python3.9/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_large.HDF5DatasetManager.batched_csv_to_hdf5(hdf5_filepath, dev_1000.name,\n",
    "                                                  dev_top_1000_path, col_name=[\"qid\", \"did\"],\n",
    "                                                  group_by_key=\"qid\", col_type=int, batch_size=int(1e7)\n",
    "                                                 )\n",
    "print(\"Training data\")\n",
    "data_large.HDF5DatasetManager.batched_csv_to_hdf5(hdf5_filepath, train_1000.name,\n",
    "                                                  train_top_1000_path, col_name=[\"qid\", \"did\"],\n",
    "                                                  group_by_key=\"qid\", col_type=int, batch_size=int(1e7)\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triple = train.create_group(\"qid-pid-nid-cluster\")\n",
    "data_large.HDF5DatasetManager.batched_csv_to_hdf5(hdf5_filepath, train_triple.name,\n",
    "                                                  train_triplet_path, col_name=[\"qid\", \"pid\", \"nid\"],\n",
    "                                                  group_by_key=\"qid\", group_by_func=lambda x : train_inverse_cluster[x],\n",
    "                                                  col_type=int, batch_size=int(1e7)\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lire",
   "language": "python",
   "name": "lire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
