{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/gerald/Documents/CPD/repository/LifelongInformationRetrieval\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of \"Document Ranking with a Pretrained Sequence-to-Sequence Model\" and adaptation to lifelong setting\n",
    "\n",
    "The aims of the proposed methods is to adress ranking using a pretrained sequence to sequence model. Contrary to most of ranking paper considering a similarity matrix between words off query and documents, authors use a directly output of sequences model. Considering as output **relevant** sequence of words reduced here to one word for positive document/query relation and an other for negative relation.\n",
    "To this end authors use the **t5** pretrained model and modelise the input as the concatenation of document and query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MSMarco corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/gerald/libraries/conda/envs/lire/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "from lire.data_tools.dataset import MSMarco\n",
    "import pandas as pd\n",
    "\n",
    "# where are or will be downloaded the corpus\n",
    "data_folder = '/local/gerald/CPD/data'\n",
    "# what split to use\n",
    "split = 'train'\n",
    "# laod the dataset with triplet output (query, positive, negative)\n",
    "\n",
    "dataset = MSMarco.MSMarcoPassageRankingDataset(data_folder,\n",
    "                                               download=True,\n",
    "                                               split=\"dev\",\n",
    "                                               storage='full',\n",
    "                                               getter='positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample of the dataset :  ('why did rachel carson write an obligation to endure', ['Carson believes that as man tries to eliminate unwanted insects and weeds, however he is actually causing more problems by polluting the environment with, for example, DDT and harming living things. Carson adds that the intensification of agriculture is causing other major problems, like newly developed or created insects and diseases.', \"The Obligation to Endure by Rachel Carson Rachel Carson's essay on The Obligation to Endure, is a very convincing argument about the harmful uses of chemicals, pesticides, herbicides, and fertilizers on the environment.\"])\n"
     ]
    }
   ],
   "source": [
    "print('sample of the dataset : ',dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local index of the query  42\n",
      "Query: \n",
      "\t\" what is the average cost of a work related back injury \"\n",
      "\n",
      "Positive Document: \n",
      "\t\" The average cost of a low-back associated workers compensation claim is nearly $8,500. This is double the cost of the average injury claim. The total estimate for the United States ranges between $50 and $100 billion per year. A large portion of this cost is directly workers compensation related. \"\n",
      "\n",
      "Negative Document: \n",
      "\t\" Provided with a workers compensation policy, protects you if you become liable for injury to an employee for a job-related injury that is not covered under the workers compensation law. Additional Coverages \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explained later\n",
    "identity_function = lambda x : x\n",
    "dataset.set_output_transformation(identity_function)\n",
    "dataset.set_query_transform(identity_function)\n",
    "dataset.set_document_transform(identity_function)\n",
    "\n",
    "local_index = 42\n",
    "print('Local index of the query ', local_index)\n",
    "q, dp, dn = dataset[local_index]\n",
    "print('Query: \\n\\t\"', q, '\"\\n')\n",
    "print('Positive Document: \\n\\t\"', dp, '\"\\n')\n",
    "print('Negative Document: \\n\\t\"', dn, '\"\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set tokenizer using HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the size of the model we will use (you can replace it)\n",
    "t5_size = 't5-small'\n",
    "\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "q, dp, dn = dataset[local_index]\n",
    "transformation = lambda x: tokenizer(x, return_tensors=\"pt\").input_ids\n",
    "dataset.set_document_transform(transformation)\n",
    "dataset.set_query_transform(transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local index of the query  42\n",
      "Query: \n",
      "\t\" tensor([[ 125,   19,    8, 1348,  583,   13,    3,    9,  161, 1341,  223, 2871,\n",
      "            1]]) \"\n",
      "\n",
      "Positive Document: \n",
      "\t\" tensor([[   37,  1348,   583,    13,     3,     9,   731,    18,  1549,  1968,\n",
      "          2765,  6107,  1988,    19,  2111, 13155,     6,  2560,     5,   100,\n",
      "            19,  1486,     8,   583,    13,     8,  1348,  2871,  1988,     5,\n",
      "            37,   792,  7037,    21,     8,   907,  1323,   620,     7,   344,\n",
      "         13309,    11, 10417,  2108,   399,   215,     5,    71,   508,  4149,\n",
      "            13,    48,   583,    19,  1461,  2765,  6107,  1341,     5,     1]]) \"\n",
      "\n",
      "Negative Document: \n",
      "\t\" tensor([[ 7740,    26,    28,     3,     9,  2765,  6107,  1291,     6,  1822,\n",
      "             7,    25,     3,    99,    25,   582,     3,  8860,    21,  2871,\n",
      "            12,    46,  3490,    21,     3,     9,   613,    18,  3897,  2871,\n",
      "            24,    19,    59,  2303,   365,     8,  2765,  6107,   973,     5,\n",
      "         11180,  5620,  2568,     1]]) \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_index = 42\n",
    "print('Local index of the query ', local_index)\n",
    "q, dp, dn = dataset[local_index]\n",
    "print('Query: \\n\\t\"', q, '\"\\n')\n",
    "print('Positive Document: \\n\\t\"', dp, '\"\\n')\n",
    "print('Negative Document: \\n\\t\"', dn, '\"\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the query and documents appearing into tokenized format. However we wants a sequence with query and documents concatenated. We use a token to separte query from document, being *\\</s>* (id 1) in the **t5** model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "transformation_output = lambda x: (torch.cat((x[0],x[1]), -1),torch.cat((x[0],x[2]), -1))\n",
    "dataset.set_output_transformation(transformation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tDetokenized query sentence positive : \n",
      "\t ['▁what', '▁fruit', '▁is', '▁native', '▁to', '▁australia', '</s>', '▁Pass', 'if', 'lor', 'a', '▁her', 'bert', 'iana', '.', '▁A', '▁rare', '▁passion', '▁fruit', '▁native', '▁to', '▁Australia', '.', '▁Fruit', 's', '▁are', '▁green', '-', 's', 'k', 'inne', 'd', ',', '▁white', '▁flesh', 'e', 'd', ',', '▁with', '▁an', '▁unknown', '▁edible', '▁rating', '.', '▁Some', '▁sources', '▁list', '▁the', '▁fruit', '▁as', '▁edible', ',', '▁sweet', '▁and', '▁tasty', ',', '▁while', '▁others', '▁list', '▁the', '▁fruits', '▁as', '▁being', '▁bitter', '▁and', '▁in', 'e', 'd', 'ible', '.', 'assi', 'f', 'lor', 'a', '▁her', 'bert', 'iana', '.', '▁A', '▁rare', '▁passion', '▁fruit', '▁native', '▁to', '▁Australia', '.', '▁Fruit', 's', '▁are', '▁green', '-', 's', 'k', 'inne', 'd', ',', '▁white', '▁flesh', 'e', 'd', ',', '▁with', '▁an', '▁unknown', '▁edible', '▁rating', '.', '▁Some', '▁sources', '▁list', '▁the', '▁fruit', '▁as', '▁edible', ',', '▁sweet', '▁and', '▁tasty', ',', '▁while', '▁others', '▁list', '▁the', '▁fruits', '▁as', '▁being', '▁bitter', '▁and', '▁in', 'e', 'd', 'ible', '.', '</s>']\n",
      "\tDetokenized query sentence negative : \n",
      "\t ['▁what', '▁fruit', '▁is', '▁native', '▁to', '▁australia', '</s>', '▁The', '▁', 'kol', 'a', '▁', 'nut', '▁is', '▁the', '▁fruit', '▁of', '▁the', '▁', 'kol', 'a', '▁tree', ',', '▁', 'a', '▁', 'gen', 'us', '▁(', 'Col', 'a', ')', '▁of', '▁trees', '▁that', '▁are', '▁native', '▁to', '▁the', '▁tropical', '▁rainforest', 's', '▁of', '▁Africa', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "query_document_positive = dataset[0][0][0]\n",
    "query_document_negative = dataset[0][1][0]\n",
    "detokenized_sentence = tokenizer.convert_ids_to_tokens(query_document_positive.tolist())\n",
    "print(\"\\tDetokenized query sentence positive : \\n\\t\", detokenized_sentence)\n",
    "detokenized_sentence = tokenizer.convert_ids_to_tokens(query_document_negative.tolist())\n",
    "print(\"\\tDetokenized query sentence negative : \\n\\t\", detokenized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The complete input preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinit transformation\n",
    "identity_function = lambda x : x\n",
    "dataset.set_output_transformation(identity_function)\n",
    "dataset.set_query_transform(identity_function)\n",
    "dataset.set_document_transform(identity_function)\n",
    "\n",
    "tokenizer_query = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "tokenizer_document = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "query_transform = lambda x: x+'</s>'\n",
    "\n",
    "output_transformation = lambda x: (x[0] + x[1], x[0] + x[2])\n",
    "\n",
    "dataset.set_query_transform(query_transform)\n",
    "dataset.set_output_transformation(output_transformation)\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "training_dataloader = data_utils.DataLoader(dataset, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('what fruit is native to australia</s>Passiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.assiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as being bitter and inedible.',\n",
       "  'types of fruit trees</s>Cherry. Cherry trees are found throughout the world. There are 40 or more varieties, ranging from bing cherry to black cherry. Along with the fruit, cherry trees produce light and delicate pinkish-white blossoms that are highly fragrant.omments. Submit. Planting fruit trees on your property not only provides you with a steady supply of organic fruit, it also allows you to beautify your yard and give oxygen back to the environment.',\n",
       "  'where is harrison city pa</s>Harrison City is a census-designated place (CDP) in Westmoreland County, Pennsylvania, United States. The population was 155 at the 2000 census.',\n",
       "  'cancer of the pancreas symptoms</s>Symptoms of Pancreatic Cancer. Pancreatic cancer may cause only vague unexplained symptoms. Pain (usually in the abdomen or back), weight loss, jaundice (yellowing of the skin and/or eyes) with or without itching, loss of appetite, nausea, change in stool, pancreatitis and recent-onset diabetes are symptoms that may indicate pancreatic cancer.',\n",
       "  \"foods that will help lower blood sugar</s>Lemons are rich in Vitamin C and their acidity helps to lower other foods' glycemic indexes. Oat and rice bran crackers make healthy snacks. Complement with organic nut butter or cheese. Other foods that stabilize blood sugar are cheese, egg yolks, berries and brewer's yeast.\",\n",
       "  'what are some foods pregnant women avoid</s>To minimize the risk of infections, pregnant women are advised to consume only pasteurized milk, cheese and fruit juice. Bottom Line: Pregnant women should not consume unpasteurized milk, cheese or fruit juice, as these foods increase the risk of bacterial infections.',\n",
       "  'how long does blood take to replenish afet lossof blood</s>The blood levels will replenish within four or five hours. However the white blood cells take 12 hours to replenish. The red blood cells take about 4 to 6 weeks to regenerate, so you need to maintain and live healthy lifestyle as well.ere are some ways on how to: The best and natural way to replenish blood is to drink plenty of water. Drink 8-12 glasses of water a day. Vegetable juices and fruit juices can also help.',\n",
       "  'what is the genus of the weeping willow tree</s>The weeping willow belongs to the Salix genus. A member of the willow family (Salicaceae), the willow genus (Salix spp.) is a cosmopolitan genus that consists of approximately 300 species of deciduous trees and shrubs.',\n",
       "  'chart of good and bad cholesterol</s>Not all cholesterol is bad for the body. There are two types of cholesterol-HDL (High Density Lipoprotein or good cholesterol) and LDL (Low Density Lipoprotein or bad cholesterol).While LDL causes blockage in arteries, HDL helps transport triglycerides to the liver for excretion.ecommended level of good cholesterol is 1.55 mmol/L and above. The recommended level of LDL (bad cholesterol) is 2.6 mmol/L or lower. Sources. Sources of HDL include onions and Omega-3 fatty acids like flax oil, fish, foods rich in fibre like grains, oats, bran etc.',\n",
       "  'is good cholesterol really good</s>Your cholesterol levels are an important measure of heart health. For HDL cholesterol, or good cholesterol, higher levels are better. By Mayo Clinic Staff. High-density lipoprotein (HDL) is known as the good cholesterol because it helps remove other forms of cholesterol from your bloodstream.'),\n",
       " ('what fruit is native to australia</s>The kola nut is the fruit of the kola tree, a genus (Cola) of trees that are native to the tropical rainforests of Africa.',\n",
       "  'types of fruit trees</s>The kola nut is the fruit of the kola tree, a genus (Cola) of trees that are native to the tropical rainforests of Africa.',\n",
       "  'where is harrison city pa</s>Nearest cities: Vandling borough, PA (1.1 miles ), Simpson, PA (2.0 miles ), Union Dale borough, PA (2.1 miles ), Carbondale, PA (2.4 miles ), Waymart borough, PA (2.4 miles ), Mayfield borough, PA (2.9 miles ), Prompton borough, PA (2.9 miles ), Jermyn borough, PA (3.1 miles ). Crime rates in Forest City by Year.',\n",
       "  \"cancer of the pancreas symptoms</s>Pancreatic cancer develops as abnormal pancreatic cells multiply rapidly in the pancreas. These cells don't die, but continue growing to form tumors. As the stages of pancreatic cancer progress in dogs, tissue in the pancreas begins to die. In the later stages of pancreatic cancer, tumors can spread to other organs, causing tissue death and organ dysfunction throughout the body.\",\n",
       "  'foods that will help lower blood sugar</s>Low hemoglobin, high blood pressure, high levels of bad cholesterol and abnormal blood sugar levels are a few factors that influence blood health. Your diet can go a long way in promoting healthy blood, and most foods that are good for the blood also promote healthy weight and general well being.n fact, foods that contain monounsaturated and polyunsaturated fat actually lower your bad cholesterol levels while increasing good cholesterol. Foods that promote healthy blood cholesterol levels include plant oils -- except for palm and coconut oil -- as well as fish, nuts and avocados.',\n",
       "  'what are some foods pregnant women avoid</s>However, you still need some niacin each day; men need about 16 mg per day and women need 14 mg per day unless they are pregnant or nursing (pregnant and breastfeeding women have higher niacin requirements).',\n",
       "  'how long does blood take to replenish afet lossof blood</s>Low hemoglobin, high blood pressure, high levels of bad cholesterol and abnormal blood sugar levels are a few factors that influence blood health. Your diet can go a long way in promoting healthy blood, and most foods that are good for the blood also promote healthy weight and general well being.n fact, foods that contain monounsaturated and polyunsaturated fat actually lower your bad cholesterol levels while increasing good cholesterol. Foods that promote healthy blood cholesterol levels include plant oils -- except for palm and coconut oil -- as well as fish, nuts and avocados.',\n",
       "  'what is the genus of the weeping willow tree</s>The kola nut is the fruit of the kola tree, a genus (Cola) of trees that are native to the tropical rainforests of Africa.',\n",
       "  'chart of good and bad cholesterol</s>Low hemoglobin, high blood pressure, high levels of bad cholesterol and abnormal blood sugar levels are a few factors that influence blood health. Your diet can go a long way in promoting healthy blood, and most foods that are good for the blood also promote healthy weight and general well being.n fact, foods that contain monounsaturated and polyunsaturated fat actually lower your bad cholesterol levels while increasing good cholesterol. Foods that promote healthy blood cholesterol levels include plant oils -- except for palm and coconut oil -- as well as fish, nuts and avocados.',\n",
       "  'is good cholesterol really good</s>Low hemoglobin, high blood pressure, high levels of bad cholesterol and abnormal blood sugar levels are a few factors that influence blood health. Your diet can go a long way in promoting healthy blood, and most foods that are good for the blood also promote healthy weight and general well being.n fact, foods that contain monounsaturated and polyunsaturated fat actually lower your bad cholesterol levels while increasing good cholesterol. Foods that promote healthy blood cholesterol levels include plant oils -- except for palm and coconut oil -- as well as fish, nuts and avocados.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "next(iter(training_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting output tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_positive = \"true\"\n",
    "token_negative = \"false\"\n",
    "index_token_positive = tokenizer(token_positive,return_tensors=\"pt\").input_ids.cuda()\n",
    "index_token_negative = tokenizer(token_negative, return_tensors=\"pt\").input_ids.cuda()\n",
    "index_token_positive = index_token_positive.repeat(10,1).cuda()\n",
    "index_token_negative = index_token_negative.repeat(10,1).cuda()\n",
    "\n",
    "\n",
    "#print(\"sep token \", tokenizer(\"true\", return_tensors=\"pt\").input_ids)\n",
    "#tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from torch import optim\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "model.cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 7.92 GiB total capacity; 5.57 GiB already allocated; 90.50 MiB free; 6.31 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-32be6d798710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_token_positive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moutputs_negative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_token_negative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_positive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_positive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, encoder_outputs, past_key_values, head_mask, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1454\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m             layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m     ):\n\u001b[1;32m    538\u001b[0m         \u001b[0mnormed_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         attention_output = self.SelfAttention(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mnormed_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/local/gerald/libraries/anaconda/envs/conda-default-ml/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 7.92 GiB total capacity; 5.57 GiB already allocated; 90.50 MiB free; 6.31 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "n_epoch = 1\n",
    "\n",
    "\n",
    "\n",
    "loss_accumulator = 0.\n",
    "for epoch in range(n_epoch):\n",
    "    for it, (positive, negative) in enumerate(training_dataloader):\n",
    "        adam_optimizer.zero_grad()\n",
    "        positive_index, negative_index =\\\n",
    "            tokenizer(positive, return_tensors=\"pt\", padding=True, max_length=512).input_ids,\\\n",
    "            tokenizer(negative, return_tensors=\"pt\", padding=True, max_length=512).input_ids\n",
    "\n",
    "        outputs_positive = model(input_ids=positive_index.cuda(), labels=index_token_positive)\n",
    "        outputs_negative = model(input_ids=negative_index.cuda(), labels=index_token_negative)\n",
    "        loss_positive = outputs_positive.loss\n",
    "        loss_negative = outputs_negative.loss\n",
    "        \n",
    "        loss = loss_positive + loss_negative\n",
    "        loss_accumulator = loss.item()\n",
    "        \n",
    "        if(it%100 == 0):\n",
    "            print(\"loss iter \",it,'/',len(training_dataloader),\" -> \", loss_accumulator/100)\n",
    "            loss_accumulator = 0.\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        adam_optimizer.step()\n",
    "        if(it == 10000):\n",
    "            break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ->  what is the cdl waveform</s>CDL TESTBED. The Common Data Link (CDL) Test Bed located at JITC is equipped with the appropriate CDL test tools and personnel to provide CDL Waveform Specification Compliance Testing and Certification. CDL vendors are charged a standard rate using a Standard Rate Schedule.\n",
      "Predicted -> ▁false  \n",
      "\n",
      "Negative ->  what is the cdl waveform</s>Indeed.com provides a good sample of salaries for all experience levels. 1  Student truck drivers earn $41,000 a year on average. 2  CDL truck drivers can expect to earn $66,000 a year on average.  OTR CDL truck drivers earn the most, with salaries averaging $82,000 a year.\n",
      "Predicted -> ▁false\n"
     ]
    }
   ],
   "source": [
    "print(\"saving the model\")\n",
    "model.cpu()\n",
    "torch.save(model, '/media/gerald/00B1B02B44A76AB2/CPD/saved_models/t5_ranking_transformer_test_5000.pth')\n",
    "model.cuda()\n",
    "positive, negative = dataset[292929]\n",
    "positive_index, negative_index =\\\n",
    "    tokenizer(positive, return_tensors=\"pt\", max_length=512).input_ids,\\\n",
    "    tokenizer(negative, return_tensors=\"pt\", max_length=512).input_ids\n",
    "outputs_positive = model.generate(input_ids=positive_index.cuda())\n",
    "outputs_negative = model.generate(input_ids=negative_index.cuda())\n",
    "\n",
    "print(\"Positive -> \", positive)\n",
    "print(\"Predicted ->\", tokenizer.convert_ids_to_tokens(outputs_positive.squeeze().tolist())[1] ,\" \\n\")\n",
    "\n",
    "\n",
    "print(\"Negative -> \", negative)\n",
    "print(\"Predicted ->\", tokenizer.convert_ids_to_tokens(outputs_negative.squeeze().tolist())[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 100/2699191 [01:42<766:33:06,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "model = torch.load('/media/gerald/00B1B02B44A76AB2/CPD/saved_models/t5_ranking_transformer_test_5000.pth')\n",
    "model.cuda()\n",
    "batch_size = 100\n",
    "training_dataloader = data_utils.DataLoader(dataset, batch_size=100, shuffle=True)\n",
    "token_positive = \"true\"\n",
    "token_negative = \"false\"\n",
    "index_token_positive = tokenizer(token_positive,return_tensors=\"pt\").input_ids\n",
    "index_token_negative = tokenizer(token_negative, return_tensors=\"pt\").input_ids\n",
    "index_token_positive = index_token_positive.repeat(100,1).cuda()\n",
    "index_token_negative = index_token_negative.repeat(100,1).cuda()\n",
    "\n",
    "import tqdm\n",
    "n_epoch = 1\n",
    "positive_score, negative_score = 0., 0.\n",
    "loss_accumulator = 0.\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for it, (positive, negative) in zip(tqdm.trange(len(training_dataloader)),(training_dataloader)):\n",
    "        positive_index, negative_index =\\\n",
    "            tokenizer(positive, return_tensors=\"pt\", padding=True, max_length=512).input_ids.cuda(),\\\n",
    "            tokenizer(negative, return_tensors=\"pt\", padding=True, max_length=512).input_ids.cuda()\n",
    "\n",
    "        outputs_positive = model(input_ids=positive_index.cuda(), labels=index_token_positive)\n",
    "        outputs_negative = model(input_ids=negative_index.cuda(), labels=index_token_negative)\n",
    "        positive_score += (outputs_positive[\"logits\"][:,0,index_token_positive[0,0]] > outputs_positive[\"logits\"][:,0,index_token_negative[0,0]]).sum()\n",
    "        negative_score += (outputs_negative[\"logits\"][:,0,index_token_negative[0,0]] > outputs_negative[\"logits\"][:,0,index_token_positive[0,0]]).sum()\n",
    "\n",
    "        if(it == 100):\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive score obtained :  94.2 %\n",
      "Negative score obtained :  72.6 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive score obtained : \", ((positive_score.item()/ (100*100)) *1e3)//1/10, \"%\")\n",
    "print(\"Negative score obtained : \", ((negative_score.item()/ (100*100)) *1e3)//1/10, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking score on the Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lire",
   "language": "python",
   "name": "lire"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
